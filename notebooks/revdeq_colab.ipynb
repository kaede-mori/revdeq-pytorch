{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reversible Deep Equilibrium Models (RevDEQ) - Colab\n",
        "\n",
        "このノートブックはGoogle ColabでRevDEQを実行するためのものです。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要なライブラリのインストール\n",
        "%pip install -q torch transformers datasets accelerate tqdm wandb pyyaml tensorboard\n",
        "\n",
        "# GPU確認\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# リポジトリのクローン（GitHubに公開後）\n",
        "# !git clone https://github.com/yourusername/RevDEQ.git\n",
        "# %cd RevDEQ\n",
        "\n",
        "# または、必要なファイルを直接アップロードする場合\n",
        "# このセルを実行して、revdeq/フォルダとtrain.pyをアップロードしてください\n",
        "import os\n",
        "print(\"Current directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モジュールのインポート\n",
        "import sys\n",
        "if '/content/RevDEQ' in os.listdir('/content'):\n",
        "    sys.path.append('/content/RevDEQ')\n",
        "else:\n",
        "    sys.path.append('.')\n",
        "\n",
        "from revdeq import RevDEQ, RevDEQConfig\n",
        "from train import prepare_dataset, RevDEQDataset\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデル設定\n",
        "config = RevDEQConfig(\n",
        "    hidden_size=768,\n",
        "    num_layers=12,\n",
        "    num_heads=12,\n",
        "    intermediate_size=3072,\n",
        "    dropout=0.1,\n",
        "    max_position_embeddings=512,\n",
        "    num_fixed_point_iterations=10,\n",
        "    fixed_point_tol=1e-5,\n",
        "    use_reversible=True,\n",
        ")\n",
        "\n",
        "# トークナイザーの読み込み\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "config.vocab_size = len(tokenizer)\n",
        "\n",
        "# モデルの初期化\n",
        "model = RevDEQ(config)\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データセットの準備\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
        "texts = [example[\"text\"] for example in dataset if len(example.get(\"text\", \"\").strip()) > 0]\n",
        "\n",
        "train_dataset = RevDEQDataset(texts[:1000], tokenizer, max_length=512)  # サンプル用に1000件のみ\n",
        "print(f\"Dataset size: {len(train_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習設定\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoints\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=10,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"tensorboard\",\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "# トレーナーの初期化\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# 学習開始\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "# モデルの保存\n",
        "trainer.save_model()\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 推論のテスト\n",
        "model.eval()\n",
        "input_text = \"The quick brown fox\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = model.generate(\n",
        "        input_ids,\n",
        "        max_length=50,\n",
        "        temperature=1.0,\n",
        "        top_k=50,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "generated_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "print(f\"Generated: {generated_text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TensorBoardで学習進捗を確認\n",
        "\n",
        "以下のコマンドでTensorBoardを起動できます（Colab内で実行する場合）:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TensorBoardの起動（Colabで使用する場合）\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir ./checkpoints/logs\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
