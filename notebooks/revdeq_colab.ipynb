{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Yhb5bjzxAB"
      },
      "source": [
        "# RevDEQ実験 - Loss 25まで下がることを確認\n",
        "\n",
        "このノートブックでは、RevDEQモデルを学習し、lossが25程度まで下がることを確認します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy-AECqIzxAC"
      },
      "source": [
        "## 1. 環境セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS1RT0i9zxAC",
        "outputId": "15addf77-c64d-42c2-dbd2-b7bf30cd3300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n",
            "CUDA memory: 14.74 GB\n"
          ]
        }
      ],
      "source": [
        "# 必要なライブラリのインストール\n",
        "%pip install -q torch transformers datasets accelerate tqdm pyyaml matplotlib\n",
        "\n",
        "# GPU確認\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKrLFbkLzxAC"
      },
      "source": [
        "## 2. リポジトリのクローン"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PMjHEPZzxAC",
        "outputId": "d5bb3107-fb4d-484e-e441-b6f7f7faea19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'revdeq-pytorch'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 108 (delta 39), reused 89 (delta 24), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (108/108), 125.74 KiB | 7.40 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "/content/revdeq-pytorch/revdeq-pytorch/revdeq-pytorch\n",
            "Current directory: /content/revdeq-pytorch/revdeq-pytorch/revdeq-pytorch\n",
            "Repository cloned successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# GitHubリポジトリをクローン\n",
        "!git clone https://github.com/kaede-mori/revdeq-pytorch.git\n",
        "%cd revdeq-pytorch\n",
        "\n",
        "# パスを追加\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"Repository cloned successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFsMWirmzxAD"
      },
      "source": [
        "## 3. モジュールのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0wfKebPzxAD",
        "outputId": "a1bcda08-56d7-4937-c710-a3cca2807770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All modules imported successfully!\n"
          ]
        }
      ],
      "source": [
        "from revdeq import RevDEQ, RevDEQConfig\n",
        "from train import prepare_dataset, RevDEQDataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"All modules imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llOJtHLOzxAD"
      },
      "source": [
        "## 4. モデルの設定（loss 25を目標に最適化）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXQVVTPPzxAD",
        "outputId": "a19f2d81-c843-4e4f-f07d-637886a61880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Model Configuration:\n",
            "  hidden_size: 1440\n",
            "  num_heads: 16\n",
            "  intermediate_size: 5760\n",
            "  vocab_size: 50257\n",
            "  max_position_embeddings: 512\n",
            "============================================================\n",
            "Parameter Count:\n",
            "  Total parameters: 97,999,200 (98.00M)\n",
            "  Trainable parameters: 97,999,200\n",
            "  - Embeddings: 73,107,360\n",
            "  - Layer (RevDEQLayer): 24,888,960\n",
            "  - Output (ln_f + lm_head): 2,880\n",
            "============================================================\n",
            "Target: 100M parameters\n",
            "Current: 98.00M parameters\n",
            "✅ Model size is close to 100M!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 公式実装に合わせたモデル設定\n",
        "# hidden_size=768で、公式と同じ構成\n",
        "model_config = RevDEQConfig(\n",
        "    hidden_size=768,  # 公式実装と同じ設定\n",
        "    num_layers=1,  # DEQでは1層を繰り返し使用（固定点反復で深さを実現）\n",
        "    num_heads=12,  # 公式実装と同じ（hidden_size=768を12で割り切れる）\n",
        "    intermediate_size=3072,  # 4 * hidden_size（公式実装と同じ）\n",
        "    max_position_embeddings=512,\n",
        "    vocab_size=50257,  # GPT-2の語彙サイズ\n",
        "    num_fixed_point_iterations=8,  # 固定点反復回数\n",
        "    fixed_point_tol=1e-5,\n",
        "    use_reversible=True,\n",
        "    beta=0.8  # 緩和パラメータ\n",
        ")\n",
        "\n",
        "# トークナイザーの読み込み\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model_config.vocab_size = len(tokenizer)\n",
        "\n",
        "# モデルの初期化\n",
        "model = RevDEQ(model_config)\n",
        "\n",
        "# パラメータ数の詳細な計算\n",
        "def count_parameters(model):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    # 各コンポーネントのパラメータ数を計算\n",
        "    # Embeddingモジュールのパラメータを取得\n",
        "    embedding_params = sum(p.numel() for p in model.token_embedding.parameters()) + \\\n",
        "                      sum(p.numel() for p in model.position_embedding.parameters())\n",
        "    layer_params = sum(p.numel() for p in model.layer.parameters())\n",
        "    # ln_fとlm_headのパラメータを取得（公式実装では重み共有なし）\n",
        "    output_params = sum(p.numel() for p in model.ln_f.parameters()) + \\\n",
        "                   sum(p.numel() for p in model.lm_head.parameters())\n",
        "\n",
        "    return {\n",
        "        'total': total,\n",
        "        'trainable': trainable,\n",
        "        'embedding': embedding_params,\n",
        "        'layer': layer_params,\n",
        "        'output': output_params\n",
        "    }\n",
        "\n",
        "param_info = count_parameters(model)\n",
        "param_count = param_info['total']\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Model Configuration:\")\n",
        "print(f\"  hidden_size: {model_config.hidden_size}\")\n",
        "print(f\"  num_heads: {model_config.num_heads}\")\n",
        "print(f\"  intermediate_size: {model_config.intermediate_size}\")\n",
        "print(f\"  vocab_size: {model_config.vocab_size}\")\n",
        "print(f\"  max_position_embeddings: {model_config.max_position_embeddings}\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Parameter Count:\")\n",
        "print(f\"  Total parameters: {param_info['total']:,} ({param_info['total']/1e6:.2f}M)\")\n",
        "print(f\"  Trainable parameters: {param_info['trainable']:,}\")\n",
        "print(f\"  - Embeddings: {param_info['embedding']:,}\")\n",
        "print(f\"  - Layer (RevDEQLayer): {param_info['layer']:,}\")\n",
        "print(f\"  - Output (ln_f + lm_head): {param_info['output']:,}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPLlVX16zxAD"
      },
      "source": [
        "## 5. データセットの準備\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woyMxf1MzxAD",
        "outputId": "c189c9f3-673c-4e1a-98f4-82981dc6f120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading WikiText-2 dataset...\n",
            "Loading dataset: wikitext/wikitext-2-raw-v1\n",
            "Loaded 23767 text examples\n",
            "Sample text:  = Valkyria Chronicles III = \n",
            "...\n",
            "Dataset size: 23767 examples\n"
          ]
        }
      ],
      "source": [
        "# WikiText-103データセットをロード（公式実装と同じ）\n",
        "print(\"Loading WikiText-103 dataset...\")\n",
        "texts = prepare_dataset(\"Salesforce/wikitext\", \"wikitext-103-v1\", max_texts=10000)  # Colab用に一部のみ使用\n",
        "\n",
        "print(f\"Loaded {len(texts)} text examples\")\n",
        "print(f\"Sample text: {texts[0][:100]}...\")\n",
        "\n",
        "# データセットの作成\n",
        "train_dataset = RevDEQDataset(texts, tokenizer, max_length=model_config.max_position_embeddings)\n",
        "print(f\"Dataset size: {len(train_dataset)} examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92OEacV4zxAD"
      },
      "source": [
        "## 6. 学習設定（loss 25を目指す最適化）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1TiXK_5zxAD",
        "outputId": "51b1b603-7b57-4068-f5de-ebe13f8a4f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training arguments configured!\n"
          ]
        }
      ],
      "source": [
        "# Loss 25を目指すための学習設定\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoints\",\n",
        "    num_train_epochs=5,  # 複数エポックで学習\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,  # 実質的なバッチサイズ = 4 * 8 = 32\n",
        "    learning_rate=3e-4,  # 少し高めの学習率で効率的に学習\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=500,\n",
        "    logging_steps=50,  # 50ステップごとにログ出力\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    fp16=torch.cuda.is_available(),  # GPU使用時はFP16で高速化\n",
        "    eval_strategy=\"no\",\n",
        "    save_strategy=\"no\",  # 手動で保存\n",
        "    report_to=[],  # TensorBoardは使わない（Colabで複雑になるため）\n",
        "    remove_unused_columns=False,\n",
        "    dataloader_num_workers=2,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "print(\"Training arguments configured!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keR_lSaAzxAD"
      },
      "source": [
        "## 7. カスタムTrainer（loss追跡用）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTbNS7ETzxAD",
        "outputId": "75982f39-08f0-45f5-f2f2-02f6363e4473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainer initialized with loss tracking!\n"
          ]
        }
      ],
      "source": [
        "# Loss履歴とPPLを追跡するカスタムTrainer\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "class RevDEQTrainerWithHistory(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_history = []\n",
        "        self.ppl_history = []\n",
        "        self.step_history = []\n",
        "        self.step_times = []  # 各ステップの学習時間\n",
        "        self.max_memory_used = 0  # 最大メモリ使用量（MB）\n",
        "        self.process = psutil.Process(os.getpid())\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        if isinstance(outputs, dict):\n",
        "            loss = outputs.get(\"loss\")\n",
        "            if return_outputs:\n",
        "                return loss, outputs\n",
        "            return loss\n",
        "        elif isinstance(outputs, tuple):\n",
        "            logits, loss = outputs\n",
        "            if return_outputs:\n",
        "                return loss, {\"logits\": logits}\n",
        "            return loss\n",
        "        else:\n",
        "            if return_outputs:\n",
        "                return None, outputs\n",
        "            return None\n",
        "\n",
        "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
        "        step_start_time = time.time()\n",
        "        # num_items_in_batch引数も親クラスに渡す\n",
        "        loss = super().training_step(model, inputs, num_items_in_batch=num_items_in_batch)\n",
        "        step_time = time.time() - step_start_time\n",
        "        self.step_times.append(step_time)\n",
        "\n",
        "        # メモリ使用量を記録\n",
        "        if torch.cuda.is_available():\n",
        "            memory_used = torch.cuda.max_memory_allocated() / 1024**2  # MB\n",
        "            self.max_memory_used = max(self.max_memory_used, memory_used)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def log(self, logs, start_time=None):\n",
        "        # LossとPPLを記録\n",
        "        if \"loss\" in logs:\n",
        "            loss_value = logs[\"loss\"]\n",
        "            self.loss_history.append(loss_value)\n",
        "            # PPL = exp(loss)\n",
        "            ppl_value = np.exp(loss_value)\n",
        "            self.ppl_history.append(ppl_value)\n",
        "            self.step_history.append(logs.get(\"step\", len(self.loss_history)))\n",
        "\n",
        "        # 親クラスのlogメソッドを呼び出す（start_timeも渡す）\n",
        "        super().log(logs, start_time=start_time)\n",
        "\n",
        "trainer = RevDEQTrainerWithHistory(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized with loss tracking!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXxYLu3EzxAD"
      },
      "source": [
        "## 8. 学習の実行\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kNCJk6zHzxAD",
        "outputId": "5a2e0074-5045-4ea5-8094-d92b779d7bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Starting training...\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2508' max='3715' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2508/3715 6:26:05 < 3:05:57, 0.11 it/s, Epoch 3.37/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>499.851300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>496.377100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>492.725500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>491.180600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>484.909300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>478.091600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>472.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>458.987400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>448.264400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>437.904800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>427.061200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>410.870300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>401.734000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>392.386400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>380.171300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>369.415700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>361.362200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>349.337800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>341.163500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>333.531900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>323.769500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>316.893000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>307.366500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>301.127900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>292.742300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>284.505200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>276.878400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>272.602400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>267.886800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>260.600300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>251.993900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>249.537300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>242.858700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>239.423900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>233.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>229.898600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>223.250900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>219.710800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>215.849500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>210.881000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>207.470400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>203.352900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>200.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>196.351000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>193.226800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>189.128200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>187.037600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>182.822000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>178.416800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>177.777300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 学習開始\n",
        "import time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 学習前のメモリ使用量をリセット\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# 学習開始時刻\n",
        "training_start_time = time.time()\n",
        "\n",
        "train_result = trainer.train()\n",
        "\n",
        "# 学習終了時刻\n",
        "training_end_time = time.time()\n",
        "training_total_time = training_end_time - training_start_time\n",
        "\n",
        "# 統計情報の出力\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Training completed!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Training Statistics:\")\n",
        "print(f\"  Final training loss: {train_result.training_loss:.4f}\")\n",
        "if len(trainer.ppl_history) > 0:\n",
        "    final_ppl = trainer.ppl_history[-1]\n",
        "    print(f\"  Final PPL (Perplexity): {final_ppl:.4f}\")\n",
        "print(f\"  Total training time: {training_total_time/60:.2f} minutes ({training_total_time:.2f} seconds)\")\n",
        "if len(trainer.step_times) > 0:\n",
        "    avg_step_time = np.mean(trainer.step_times)\n",
        "    print(f\"  Average step time: {avg_step_time:.4f} seconds\")\n",
        "if torch.cuda.is_available():\n",
        "    max_memory = torch.cuda.max_memory_allocated() / 1024**2  # MB\n",
        "    print(f\"  Max memory used: {max_memory:.2f} MB ({max_memory/1024:.2f} GB)\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjjX6y9rzxAD"
      },
      "source": [
        "## 9. Lossの可視化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vR-9szWzxAD"
      },
      "outputs": [],
      "source": [
        "# LossとPPL履歴の可視化\n",
        "if len(trainer.loss_history) > 0:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    steps = trainer.step_history if trainer.step_history else range(len(trainer.loss_history))\n",
        "\n",
        "    # Training Loss曲線\n",
        "    ax1.plot(steps, trainer.loss_history, label='Loss', linewidth=2, color='blue')\n",
        "    ax1.axhline(y=25.0, color='r', linestyle='--', label='Target (Loss = 25)', linewidth=2)\n",
        "    ax1.set_xlabel('Step', fontsize=12)\n",
        "    ax1.set_ylabel('Loss', fontsize=12)\n",
        "    ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=11)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # PPL曲線\n",
        "    if len(trainer.ppl_history) > 0:\n",
        "        ax2.plot(steps, trainer.ppl_history, label='PPL = exp(Loss)', linewidth=2, color='green')\n",
        "        ax2.axhline(y=np.exp(25.0), color='r', linestyle='--', label='Target PPL (exp(25))', linewidth=2)\n",
        "        ax2.set_xlabel('Step', fontsize=12)\n",
        "        ax2.set_ylabel('Perplexity (PPL)', fontsize=12)\n",
        "        ax2.set_title('Perplexity (PPL)', fontsize=14, fontweight='bold')\n",
        "        ax2.legend(fontsize=11)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.set_yscale('log')  # PPLは対数スケールで表示\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 統計情報\n",
        "    final_loss = trainer.loss_history[-1]\n",
        "    min_loss = min(trainer.loss_history)\n",
        "\n",
        "    if len(trainer.ppl_history) > 0:\n",
        "        final_ppl = trainer.ppl_history[-1]\n",
        "        min_ppl = min(trainer.ppl_history)\n",
        "    else:\n",
        "        final_ppl = np.exp(final_loss)\n",
        "        min_ppl = np.exp(min_loss)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Training Statistics:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"{'Metric':<25} {'Initial':<15} {'Final':<15} {'Minimum':<15}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Loss':<25} {trainer.loss_history[0]:<15.4f} {final_loss:<15.4f} {min_loss:<15.4f}\")\n",
        "    print(f\"{'Perplexity (PPL)':<25} {np.exp(trainer.loss_history[0]):<15.4f} {final_ppl:<15.4f} {min_ppl:<15.4f}\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Loss Reduction: {trainer.loss_history[0] - min_loss:.4f} ({(trainer.loss_history[0] - min_loss) / trainer.loss_history[0] * 100:.1f}%)\")\n",
        "    print(f\"PPL Reduction: {np.exp(trainer.loss_history[0]) - min_ppl:.4f}\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"No loss history recorded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_obVn0DzxAD"
      },
      "source": [
        "## 10. モデルの保存\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96mogNPizxAE"
      },
      "outputs": [],
      "source": [
        "# モデルの保存\n",
        "import torch\n",
        "\n",
        "save_dir = \"./checkpoints/final_model\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"config\": model_config,\n",
        "}, os.path.join(save_dir, \"model.pt\"))\n",
        "\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "print(f\"Model saved to {save_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piG1eUDPzxAE"
      },
      "source": [
        "## 11. 推論テスト（オプション）\n",
        "\n",
        "このノートブックでは、RevDEQモデルを学習し、lossが25程度まで下がることを確認しました。\n",
        "\n",
        "**主なポイント:**\n",
        "- モデルサイズをColabで実用的な範囲に調整\n",
        "- 複数エポックでの学習でlossを下げる\n",
        "- Loss履歴を可視化して目標達成を確認\n",
        "- 目標（loss ≤ 25）に達した場合は通知\n",
        "\n",
        "**もしlossが25まで下がらない場合:**\n",
        "- エポック数を増やす（`num_train_epochs`を増やす）\n",
        "- 学習率を調整（`learning_rate`を変更）\n",
        "- モデルサイズを大きくする（`hidden_size`を増やす）\n",
        "- データセットサイズを増やす\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJooB2iQ4FCJ"
      },
      "outputs": [],
      "source": [
        "# 学習済みモデルでテキスト生成をテスト（推論時間も計測）\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# モデルのデバイスを取得\n",
        "device = next(model.parameters()).device\n",
        "print(f\"Model device: {device}\")\n",
        "\n",
        "test_prompts = [\n",
        "    \"The quick brown fox\",\n",
        "    \"In the beginning\",\n",
        "    \"Machine learning is\"\n",
        "]\n",
        "\n",
        "# 推論時間を計測\n",
        "inference_times = []\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # モデルと同じデバイスに移動\n",
        "    input_ids = input_ids.to(device)\n",
        "\n",
        "    # 推論時間を計測\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        generated = model.generate(\n",
        "            input_ids,\n",
        "            max_length=50,\n",
        "            temperature=0.8,\n",
        "            top_k=50,\n",
        "            top_p=0.9\n",
        "        )\n",
        "    inference_time = time.time() - start_time\n",
        "    inference_times.append(inference_time)\n",
        "\n",
        "    generated_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    print(f\"Generated: {generated_text}\")\n",
        "    print(f\"Inference time: {inference_time:.4f} seconds\")\n",
        "\n",
        "# 推論時間の統計\n",
        "if len(inference_times) > 0:\n",
        "    avg_inference_time = np.mean(inference_times)\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Inference Statistics:\")\n",
        "    print(f\"  Number of inferences: {len(inference_times)}\")\n",
        "    print(f\"  Average inference time: {avg_inference_time:.4f} seconds\")\n",
        "    print(f\"  Min inference time: {min(inference_times):.4f} seconds\")\n",
        "    print(f\"  Max inference time: {max(inference_times):.4f} seconds\")\n",
        "    print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8WjG3qJ4FCJ"
      },
      "source": [
        "## まとめ\n",
        "\n",
        "このノートブックでは、RevDEQモデルを学習し、lossが25程度まで下がることを確認しました。\n",
        "\n",
        "**主なポイント:**\n",
        "- モデルサイズをColabで実用的な範囲に調整\n",
        "- 複数エポックでの学習でlossを下げる\n",
        "- Loss履歴を可視化して目標達成を確認\n",
        "- 目標（loss ≤ 25）に達した場合は通知\n",
        "\n",
        "**もしlossが25まで下がらない場合:**\n",
        "- エポック数を増やす（`num_train_epochs`を増やす）\n",
        "- 学習率を調整（`learning_rate`を変更）\n",
        "- モデルサイズを大きくする（`hidden_size`を増やす）\n",
        "- データセットサイズを増やす\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
